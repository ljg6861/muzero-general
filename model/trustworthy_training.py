#!/usr/bin/env python3
"""
Trustworthy Cognitive LLM Training System
========================================
Enhanced with proper per-token loss computation, ablation capabilities,
mixed precision training, and comprehensive evaluation metrics.
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
from torch.cuda.amp import GradScaler, autocast
import numpy as np
import json
import pickle
import os
import shutil
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import math
import time
from tqdm import tqdm
import logging

from cognitive_llm import CognitiveLLM, CognitiveLLMConfig


class EarlyStopping:
    """Early stopping utility to prevent overfitting."""
    
    def __init__(self, patience: int = 3, min_delta: float = 0.001, mode: str = 'min'):
        """
        Initialize early stopping.
        
        Args:
            patience: Number of evaluations to wait for improvement
            min_delta: Minimum change to qualify as improvement
            mode: 'min' for metrics that should decrease, 'max' for metrics that should increase
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_value = float('inf') if mode == 'min' else float('-inf')
        self.early_stop = False
        self.history = []
    
    def __call__(self, metric_value: float) -> bool:
        """
        Check if training should stop.
        
        Args:
            metric_value: Current value of the monitored metric
            
        Returns:
            True if training should stop, False otherwise
        """
        self.history.append(metric_value)
        
        if self.mode == 'min':
            improved = metric_value < (self.best_value - self.min_delta)
        else:
            improved = metric_value > (self.best_value + self.min_delta)
        
        if improved:
            self.best_value = metric_value
            self.counter = 0
            print(f"   üìà Metric improved to {metric_value:.4f}")
        else:
            self.counter += 1
            print(f"   ‚ö†Ô∏è  No improvement for {self.counter}/{self.patience} evaluations (current: {metric_value:.4f}, best: {self.best_value:.4f})")
            
            if self.counter >= self.patience:
                self.early_stop = True
                print(f"   üõë Early stopping triggered after {self.patience} evaluations without improvement")
        
        return self.early_stop
    
    def reset(self):
        """Reset early stopping state."""
        self.counter = 0
        self.best_value = float('inf') if self.mode == 'min' else float('-inf')
        self.early_stop = False
        self.history = []


@dataclass
class TrainingConfig:
    """Configuration for training the Cognitive LLM."""
    # Training parameters
    num_epochs: int = 10
    learning_rate: float = 1e-4
    cognitive_learning_rate: float = 5e-5
    weight_decay: float = 0.02
    warmup_steps: int = 1000
    max_grad_norm: float = 1.0
    
    # Mixed Precision Training
    use_mixed_precision: bool = True
    grad_scaler_init_scale: float = 2**16
    grad_scaler_growth_factor: float = 2.0
    grad_scaler_backoff_factor: float = 0.5
    grad_scaler_growth_interval: int = 2000
    
    # Optimization
    beta1: float = 0.9
    beta2: float = 0.999
    eps: float = 1e-8
    
    # Checkpointing
    save_steps: int = 1000
    eval_steps: int = 500
    logging_steps: int = 100
    max_checkpoints: int = 5
    
    # Early Stopping Parameters
    early_stopping_patience: int = 3
    early_stopping_min_delta: float = 0.001
    early_stopping_metric: str = "eval_loss"
    
    # Enhanced Regularization
    dropout_prob: float = 0.15
    attention_dropout: float = 0.15
    layer_dropout: float = 0.0
    gradient_noise_scale: float = 0.0
    
    # Data Regularization
    label_smoothing: float = 0.1
    data_augmentation: bool = True
    shuffle_training_data: bool = True
    
    # Learning Rate Scheduling
    lr_scheduler_type: str = "cosine_with_restarts"
    lr_scheduler_warmup_ratio: float = 0.05  # 5% warmup (3-5% recommended)
    lr_min_ratio: float = 0.01
    
    # Training dynamics
    gradient_accumulation_steps: int = 4
    dataloader_num_workers: int = 4
    pin_memory: bool = True
    
    # Cognitive enhancement control (for ablation)
    enable_cognitive_enhancement: bool = True
    cognitive_loss_weight: float = 0.1
    concept_formation_weight: float = 0.3
    causal_reasoning_weight: float = 0.4
    meta_learning_weight: float = 0.3
    
    # Resume training
    resume_from_checkpoint: Optional[str] = None
    
    # Paths
    output_dir: str = "cognitive_llm_output"
    logging_dir: str = "logs"
    cache_dir: str = "cache"


class TrustworthyLossFunction:
    """
    Enhanced loss function with proper per-token mean calculation
    and comprehensive evaluation metrics for trustworthy training.
    """
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        # Use reduction='none' to get per-token losses for proper mean calculation
        self.language_loss = nn.CrossEntropyLoss(reduction='none', ignore_index=-100)
        self.concept_loss = nn.MSELoss()
        self.causal_loss = nn.BCEWithLogitsLoss()
        
    def calculate_language_modeling_loss(self, logits, labels, attention_mask=None):
        """
        Calculate language modeling loss with proper per-token mean calculation.
        
        Returns both mean loss and detailed metrics for trustworthy evaluation.
        """
        # Shift for causal language modeling: predict next token
        shift_logits = logits[..., :-1, :].contiguous()  # Remove last token prediction
        shift_labels = labels[..., 1:].contiguous()      # Remove first token (input)
        
        # Create attention mask for shifted sequence
        if attention_mask is not None:
            shift_attention_mask = attention_mask[..., 1:].contiguous()
        else:
            shift_attention_mask = torch.ones_like(shift_labels)
        
        # Calculate per-token losses
        per_token_losses = self.language_loss(
            shift_logits.view(-1, shift_logits.size(-1)), 
            shift_labels.view(-1)
        )
        per_token_losses = per_token_losses.view(shift_labels.shape)  # Reshape back to [batch, seq_len-1]
        
        # Apply attention mask to ignore padding tokens (loss weight = 0 for padding)
        masked_losses = per_token_losses * shift_attention_mask.float()
        
        # Calculate metrics
        valid_tokens = shift_attention_mask.sum()
        total_loss_sum = masked_losses.sum()
        mean_loss = total_loss_sum / valid_tokens if valid_tokens > 0 else torch.tensor(0.0, device=logits.device)
        
        # Sequence length statistics
        batch_size = shift_labels.size(0)
        seq_lengths = shift_attention_mask.sum(dim=1).float()  # Valid tokens per sequence
        mean_seq_len = seq_lengths.mean()
        
        return {
            'loss_mean': mean_loss,
            'loss_sum': total_loss_sum,
            'n_tokens': valid_tokens.item(),
            'seq_len_mean': mean_seq_len.item(),
            'per_token_losses': per_token_losses,
            'valid_mask': shift_attention_mask
        }
    
    def calculate_concept_formation_loss(self, hidden_states, concept_targets=None):
        """Loss for concept formation quality."""
        if concept_targets is None:
            # Self-supervised concept formation loss
            batch_size, seq_len, hidden_size = hidden_states.shape
            concepts = hidden_states.view(batch_size, -1)
            
            # Diversity loss - encourage different concepts to be distinct
            concept_similarity = torch.mm(concepts, concepts.t())
            diversity_loss = torch.mean(torch.triu(concept_similarity, diagonal=1) ** 2)
            
            # Coherence loss - encourage concepts within sequence to be coherent
            seq_concepts = hidden_states.mean(dim=1)  # Average over sequence
            coherence_target = seq_concepts.unsqueeze(1).expand(-1, seq_len, -1)
            coherence_loss = self.concept_loss(hidden_states, coherence_target)
            
            return 0.5 * diversity_loss + 0.5 * coherence_loss
        else:
            return self.concept_loss(hidden_states, concept_targets)
    
    def calculate_causal_reasoning_loss(self, attention_probs):
        """Loss for causal reasoning quality based on attention patterns."""
        batch_size, num_heads, seq_len, _ = attention_probs.shape
        
        # Causal mask - future tokens should have zero attention
        causal_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)
        causal_mask = causal_mask.to(attention_probs.device)
        
        # Calculate violation of causal constraints
        future_attention = attention_probs * causal_mask.unsqueeze(0).unsqueeze(0)
        causal_violation = torch.mean(future_attention ** 2)
        
        return causal_violation
    
    def calculate_total_loss(self, outputs, labels, attention_mask=None, epoch=0, enable_cognitive=True):
        """
        Calculate total loss combining all objectives with proper per-token accounting.
        
        Args:
            outputs: Model outputs containing logits, hidden_states, attention_probs
            labels: Target token ids [batch_size, seq_len]
            attention_mask: Attention mask [batch_size, seq_len]
            epoch: Current training epoch
            enable_cognitive: Whether to include cognitive losses (for ablation)
        
        Returns:
            Dictionary with detailed loss metrics including per-token statistics
        """
        logits = outputs['logits']
        hidden_states = outputs['hidden_states']
        attention_probs = outputs.get('attention_probs', [])
        
        # Language modeling loss with detailed metrics
        lm_metrics = self.calculate_language_modeling_loss(logits, labels, attention_mask)
        lm_loss = lm_metrics['loss_mean']
        
        # Initialize cognitive losses
        concept_loss = torch.tensor(0.0, device=logits.device)
        causal_loss = torch.tensor(0.0, device=logits.device)
        
        # Only calculate cognitive losses if enabled (for baseline vs cognitive comparison)
        if enable_cognitive and self.config.enable_cognitive_enhancement and self.config.cognitive_loss_weight > 0:
            # Cognitive enhancement losses
            if hidden_states is not None:
                concept_loss = self.calculate_concept_formation_loss(hidden_states)
            
            # Average attention across layers for causal loss
            if attention_probs:
                avg_attention = torch.stack(attention_probs).mean(dim=0)
                causal_loss = self.calculate_causal_reasoning_loss(avg_attention)
        
        # Combine losses with weights
        total_loss = lm_loss
        if enable_cognitive and self.config.enable_cognitive_enhancement:
            total_loss += (self.config.cognitive_loss_weight * 
                          self.config.concept_formation_weight * concept_loss +
                          self.config.cognitive_loss_weight * 
                          self.config.causal_reasoning_weight * causal_loss)
        
        # Calculate perplexity for verification: PPL = exp(loss_mean)
        perplexity = torch.exp(lm_loss.clamp(max=100))  # Clamp to prevent overflow
        
        return {
            'total_loss': total_loss,
            'language_modeling_loss': lm_loss,
            'concept_formation_loss': concept_loss,
            'causal_reasoning_loss': causal_loss,
            # Detailed LM metrics for trustworthy evaluation
            'lm_loss_mean': lm_metrics['loss_mean'],
            'lm_loss_sum': lm_metrics['loss_sum'],
            'n_tokens': lm_metrics['n_tokens'],
            'seq_len_mean': lm_metrics['seq_len_mean'],
            'perplexity': perplexity,
            # Verification: PPL should equal exp(loss_mean)
            'ppl_verification': torch.exp(lm_metrics['loss_mean']).clamp(max=1e6)
        }


class ModelCheckpoint:
    """Enhanced model checkpointing with cognitive state preservation."""
    
    def __init__(self, config: TrainingConfig):
        self.config = config
        self.output_dir = config.output_dir
        self.max_checkpoints = config.max_checkpoints
        
        # Ensure directories exist
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(os.path.join(self.output_dir, "checkpoints"), exist_ok=True)
        
        self.checkpoint_history = []
        
    def save_checkpoint(self, 
                       model: CognitiveLLM, 
                       optimizer: optim.Optimizer,
                       lr_scheduler,
                       epoch: int,
                       step: int,
                       loss: float,
                       eval_metrics: Dict[str, float] = None):
        """Save a complete training checkpoint."""
        
        checkpoint_name = f"checkpoint-epoch-{epoch}-step-{step}"
        checkpoint_path = os.path.join(self.output_dir, "checkpoints", checkpoint_name)
        
        # Create checkpoint directory
        os.makedirs(checkpoint_path, exist_ok=True)
        
        # Save model and config
        model.save_model(checkpoint_path)
        
        # Convert eval_metrics to JSON-serializable format
        json_safe_eval_metrics = {}
        if eval_metrics:
            for key, value in eval_metrics.items():
                if isinstance(value, torch.Tensor):
                    json_safe_eval_metrics[key] = value.item() if value.numel() == 1 else value.tolist()
                elif isinstance(value, (int, float, str, bool, list, dict)):
                    json_safe_eval_metrics[key] = value
                else:
                    json_safe_eval_metrics[key] = str(value)
        
        # Save training state (JSON-serializable only)
        training_state = {
            'epoch': epoch,
            'step': step,
            'loss': loss.item() if isinstance(loss, torch.Tensor) else loss,
            'training_config': asdict(self.config),
            'eval_metrics': json_safe_eval_metrics,
            'timestamp': datetime.now().isoformat(),
            'torch_version': torch.__version__,
            'model_config': asdict(model.config)
        }
        
        try:
            with open(os.path.join(checkpoint_path, 'training_state.json'), 'w') as f:
                json.dump(training_state, f, indent=2)
        except TypeError as e:
            print(f"Warning: Could not serialize training state to JSON: {e}")
            # Save as pickle as fallback
            with open(os.path.join(checkpoint_path, 'training_state.pkl'), 'wb') as f:
                pickle.dump(training_state, f)
        
        # Save optimizer state separately (can be large)
        torch.save(optimizer.state_dict(), os.path.join(checkpoint_path, 'optimizer.pt'))
        if lr_scheduler:
            torch.save(lr_scheduler.state_dict(), os.path.join(checkpoint_path, 'scheduler.pt'))
        
        # Update checkpoint history
        self.checkpoint_history.append({
            'name': checkpoint_name,
            'path': checkpoint_path,
            'epoch': epoch,
            'step': step,
            'loss': loss,
            'timestamp': datetime.now().isoformat()
        })
        
        # Remove old checkpoints if exceeding max_checkpoints
        if len(self.checkpoint_history) > self.max_checkpoints:
            old_checkpoint = self.checkpoint_history.pop(0)
            if os.path.exists(old_checkpoint['path']):
                shutil.rmtree(old_checkpoint['path'])
                print(f"Removed old checkpoint: {old_checkpoint['name']}")
        
        # Save checkpoint history
        with open(os.path.join(self.output_dir, 'checkpoint_history.json'), 'w') as f:
            json.dump(self.checkpoint_history, f, indent=2)
        
        print(f"Saved checkpoint: {checkpoint_name} (loss: {loss:.4f})")
        
        return checkpoint_path


class TrustworthyCognitiveLLMTrainer:
    """
    Main trainer class for Cognitive LLM with trustworthy evaluation,
    mixed precision training, and proper ablation capabilities.
    """
    
    def __init__(self, 
                 model: CognitiveLLM,
                 train_dataloader: DataLoader,
                 eval_dataloader: DataLoader = None,
                 config: TrainingConfig = None):
        
        self.model = model
        self.train_dataloader = train_dataloader
        self.eval_dataloader = eval_dataloader
        self.config = config or TrainingConfig()
        
        # Setup device
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
        
        # Setup mixed precision training
        self.use_amp = self.config.use_mixed_precision and torch.cuda.is_available()
        if self.use_amp:
            self.scaler = GradScaler(
                init_scale=self.config.grad_scaler_init_scale,
                growth_factor=self.config.grad_scaler_growth_factor,
                backoff_factor=self.config.grad_scaler_backoff_factor,
                growth_interval=self.config.grad_scaler_growth_interval
            )
            print(f"   ‚ö° Mixed precision training enabled")
        else:
            self.scaler = None
            print(f"   üîß Standard precision training")
        
        # Setup optimizer with proper weight decay exclusions
        self.optimizer = self._create_optimizer()
        self.lr_scheduler = self._create_lr_scheduler()
        
        # Setup loss function
        self.loss_function = TrustworthyLossFunction(self.config)
        
        # Setup checkpointing
        self.checkpoint_manager = ModelCheckpoint(self.config)
        
        # Setup early stopping
        self.early_stopping = EarlyStopping(
            patience=self.config.early_stopping_patience,
            min_delta=self.config.early_stopping_min_delta,
            mode='min' if 'loss' in self.config.early_stopping_metric else 'max'
        )
        
        # Setup logging
        self.setup_logging()
        
        # Training state
        self.current_epoch = 0
        self.current_step = 0
        self.best_eval_loss = float('inf')
        self.training_stopped_early = False
        
        # Resume from checkpoint if specified
        if self.config.resume_from_checkpoint:
            self.resume_from_checkpoint()
    
    def _create_optimizer(self):
        """Create optimizer with different learning rates and proper weight decay exclusions."""
        # Separate parameters for different learning rates and weight decay exclusions
        cognitive_params = []
        transformer_params = []
        no_decay_params = []
        
        for name, param in self.model.named_parameters():
            # Exclude LayerNorm and bias from weight decay
            if any(nd in name for nd in ['bias', 'LayerNorm.weight', 'layer_norm.weight']):
                no_decay_params.append(param)
            elif any(x in name for x in ['cognitive', 'concept', 'causal', 'reasoning']):
                cognitive_params.append(param)
            else:
                transformer_params.append(param)
        
        optimizer = optim.AdamW([
            {'params': transformer_params, 'lr': self.config.learning_rate, 'weight_decay': self.config.weight_decay},
            {'params': cognitive_params, 'lr': self.config.cognitive_learning_rate, 'weight_decay': self.config.weight_decay},
            {'params': no_decay_params, 'lr': self.config.learning_rate, 'weight_decay': 0.0}
        ], 
        betas=(self.config.beta1, self.config.beta2),
        eps=self.config.eps)
        
        return optimizer
    
    def _create_lr_scheduler(self):
        """Create learning rate scheduler with warmup and cosine decay."""
        total_steps = len(self.train_dataloader) * self.config.num_epochs // self.config.gradient_accumulation_steps
        warmup_steps = int(total_steps * self.config.lr_scheduler_warmup_ratio)
        
        def lr_lambda(step):
            if step < warmup_steps:
                return step / warmup_steps
            else:
                # Cosine decay after warmup
                progress = (step - warmup_steps) / (total_steps - warmup_steps)
                return self.config.lr_min_ratio + (1 - self.config.lr_min_ratio) * 0.5 * (1 + math.cos(math.pi * progress))
        
        return optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda)
    
    def setup_logging(self):
        """Setup logging and tensorboard."""
        log_dir = os.path.join(self.config.output_dir, self.config.logging_dir)
        os.makedirs(log_dir, exist_ok=True)
        
        # Setup file logging
        logging.basicConfig(
            filename=os.path.join(log_dir, 'training.log'),
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        
        # Setup tensorboard
        self.writer = SummaryWriter(log_dir)
        
        print(f"Logging to {log_dir}")
    
    def train_epoch(self, epoch: int, enable_cognitive: bool = True):
        """
        Train for one epoch with proper per-token loss tracking and mixed precision.
        
        Args:
            epoch: Current epoch number
            enable_cognitive: Whether to enable cognitive enhancements (for ablation)
        """
        self.model.train()
        total_loss = 0
        total_lm_loss = 0
        total_concept_loss = 0
        total_causal_loss = 0
        total_tokens = 0
        total_sequences = 0
        total_grad_norm = 0
        num_grad_updates = 0
        
        progress_bar = tqdm(self.train_dataloader, desc=f"Epoch {epoch} ({'Cognitive' if enable_cognitive else 'Baseline LM'})")
        
        for batch_idx, batch in enumerate(progress_bar):
            # Move batch to device
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch.get('attention_mask', None)
            if attention_mask is not None:
                attention_mask = attention_mask.to(self.device)
            
            # Forward pass with mixed precision
            if self.use_amp:
                with autocast():
                    # Forward pass (with or without cognitive enhancement)
                    if hasattr(self.model, 'forward') and 'enable_cognitive' in self.model.forward.__code__.co_varnames:
                        outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids, 
                                           enable_cognitive=enable_cognitive)
                    else:
                        outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids)
                    
                    # Calculate loss with detailed metrics
                    loss_dict = self.loss_function.calculate_total_loss(
                        outputs, input_ids, attention_mask, epoch, enable_cognitive
                    )
                    loss = loss_dict['total_loss']
            else:
                # Standard precision forward pass
                if hasattr(self.model, 'forward') and 'enable_cognitive' in self.model.forward.__code__.co_varnames:
                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids, 
                                       enable_cognitive=enable_cognitive)
                else:
                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids)
                
                # Calculate loss with detailed metrics
                loss_dict = self.loss_function.calculate_total_loss(
                    outputs, input_ids, attention_mask, epoch, enable_cognitive
                )
                loss = loss_dict['total_loss']
            
            # Backward pass with gradient accumulation
            loss = loss / self.config.gradient_accumulation_steps
            
            if self.use_amp:
                self.scaler.scale(loss).backward()
            else:
                loss.backward()
            
            # Update weights
            if (batch_idx + 1) % self.config.gradient_accumulation_steps == 0:
                # Calculate and log gradient norm before clipping
                if self.use_amp:
                    # Unscale gradients for gradient norm calculation
                    self.scaler.unscale_(self.optimizer)
                    grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)
                    
                    # Check for gradient overflow
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.max_grad_norm)
                    self.optimizer.step()
                
                self.lr_scheduler.step()
                self.optimizer.zero_grad()
                
                self.current_step += 1
                total_grad_norm += grad_norm.item()
                num_grad_updates += 1
                
                # Enhanced logging with per-token metrics and gradient info
                if self.current_step % self.config.logging_steps == 0:
                    enhanced_loss_dict = {
                        **loss_dict, 
                        'grad_norm': grad_norm.item(),
                        'lr': self.lr_scheduler.get_last_lr()[0],
                        'scaler_scale': self.scaler.get_scale() if self.use_amp else 1.0
                    }
                    self._log_training_step(enhanced_loss_dict)
                
                # Evaluation with proper eval mode
                if self.eval_dataloader and self.current_step % self.config.eval_steps == 0:
                    eval_metrics = self.evaluate(enable_cognitive=enable_cognitive)
                    self._log_evaluation(eval_metrics)
                    
                    # Check early stopping
                    should_stop = self.early_stopping(eval_metrics['eval_loss'])
                    if should_stop:
                        self.training_stopped_early = True
                        print("üõë Early stopping triggered!")
                        return None  # Signal to stop training
                
                # Checkpointing
                if self.current_step % self.config.save_steps == 0:
                    eval_metrics_for_checkpoint = eval_metrics if 'eval_metrics' in locals() else None
                    self.checkpoint_manager.save_checkpoint(
                        self.model, self.optimizer, self.lr_scheduler,
                        epoch, self.current_step, loss.item(), eval_metrics=eval_metrics_for_checkpoint
                    )
            
            # Update progress bar with detailed metrics
            total_loss += loss.item()
            total_lm_loss += loss_dict['language_modeling_loss'].item()
            total_concept_loss += loss_dict['concept_formation_loss'].item()
            total_causal_loss += loss_dict['causal_reasoning_loss'].item()
            total_tokens += loss_dict['n_tokens']
            total_sequences += input_ids.size(0)
            
            # Verify PPL calculation
            ppl_calculated = loss_dict['perplexity'].item()
            ppl_verification = loss_dict['ppl_verification'].item()
            ppl_match = abs(ppl_calculated - ppl_verification) < 0.01
            
            # Average gradient norm for display
            avg_grad_norm = total_grad_norm / max(num_grad_updates, 1)
            
            progress_bar.set_postfix({
                'loss': f"{loss.item():.4f}",
                'lm_loss': f"{loss_dict['language_modeling_loss'].item():.4f}",
                'ppl': f"{ppl_calculated:.1f}",
                'ppl_ok': "‚úì" if ppl_match else "‚úó",
                'tokens': f"{loss_dict['n_tokens']:.0f}",
                'grad_norm': f"{avg_grad_norm:.3f}",
                'lr': f"{self.lr_scheduler.get_last_lr()[0]:.2e}",
                'amp': "‚ö°" if self.use_amp else "üîß"
            })
        
        # Calculate epoch averages
        num_batches = len(self.train_dataloader)
        avg_loss = total_loss / num_batches
        avg_lm_loss = total_lm_loss / num_batches
        avg_concept_loss = total_concept_loss / num_batches
        avg_causal_loss = total_causal_loss / num_batches
        avg_tokens_per_batch = total_tokens / num_batches if num_batches > 0 else 0
        avg_grad_norm = total_grad_norm / max(num_grad_updates, 1)
        
        return {
            'avg_loss': avg_loss,
            'avg_lm_loss': avg_lm_loss,
            'avg_concept_loss': avg_concept_loss,
            'avg_causal_loss': avg_causal_loss,
            'total_tokens': total_tokens,
            'total_sequences': total_sequences,
            'avg_tokens_per_batch': avg_tokens_per_batch,
            'avg_grad_norm': avg_grad_norm,
            'num_grad_updates': num_grad_updates
        }
    
    def evaluate(self, enable_cognitive: bool = True):
        """
        Evaluate the model with proper eval mode and detailed per-token metrics.
        
        Args:
            enable_cognitive: Whether to enable cognitive enhancements during evaluation
        """
        if not self.eval_dataloader:
            return {}
        
        # Ensure proper evaluation mode
        self.model.eval()
        
        total_loss = 0
        total_lm_loss = 0
        total_concept_loss = 0
        total_causal_loss = 0
        total_tokens = 0
        total_sequences = 0
        all_perplexities = []
        
        with torch.no_grad():  # Disable gradients for evaluation
            for batch in tqdm(self.eval_dataloader, desc=f"Evaluating ({'Cognitive' if enable_cognitive else 'Baseline'})"):
                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch.get('attention_mask', None)
                if attention_mask is not None:
                    attention_mask = attention_mask.to(self.device)
                
                # Forward pass with cognitive enhancement control
                if hasattr(self.model, 'forward') and 'enable_cognitive' in self.model.forward.__code__.co_varnames:
                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids, 
                                       enable_cognitive=enable_cognitive)
                else:
                    outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids)
                
                # Calculate loss with detailed metrics
                loss_dict = self.loss_function.calculate_total_loss(
                    outputs, input_ids, attention_mask, epoch=0, enable_cognitive=enable_cognitive
                )
                
                # Accumulate metrics
                total_loss += loss_dict['total_loss'].item()
                total_lm_loss += loss_dict['language_modeling_loss'].item()
                total_concept_loss += loss_dict['concept_formation_loss'].item()
                total_causal_loss += loss_dict['causal_reasoning_loss'].item()
                total_tokens += loss_dict['n_tokens']
                total_sequences += input_ids.size(0)
                
                # Track perplexity for verification
                all_perplexities.append(loss_dict['perplexity'].item())
        
        # Calculate averages
        num_batches = len(self.eval_dataloader)
        avg_loss = total_loss / num_batches
        avg_lm_loss = total_lm_loss / num_batches
        avg_concept_loss = total_concept_loss / num_batches
        avg_causal_loss = total_causal_loss / num_batches
        avg_tokens_per_batch = total_tokens / num_batches if num_batches > 0 else 0
        
        # Calculate perplexity: PPL = exp(loss_mean)
        # Use the language modeling loss for perplexity calculation
        perplexity = math.exp(min(avg_lm_loss, 100))  # Clamp to prevent overflow
        avg_perplexity = sum(all_perplexities) / len(all_perplexities) if all_perplexities else 0
        
        # Verify PPL calculation consistency
        ppl_verification_passed = abs(perplexity - avg_perplexity) < (perplexity * 0.01)  # 1% tolerance
        
        # Restore training mode
        self.model.train()
        
        return {
            'eval_loss': avg_loss,
            'eval_lm_loss': avg_lm_loss,
            'eval_concept_loss': avg_concept_loss,
            'eval_causal_loss': avg_causal_loss,
            'perplexity': perplexity,
            'perplexity_verification': avg_perplexity,
            'ppl_verification_passed': ppl_verification_passed,
            'total_tokens': total_tokens,
            'total_sequences': total_sequences,
            'avg_tokens_per_batch': avg_tokens_per_batch,
            'n_eval_batches': num_batches
        }
    
    def overfitting_test(self, target_loss: float = 0.05, max_steps: int = 500):
        """
        Sanity test: overfit a single batch to near-zero loss.
        This verifies that masking and labels are correct.
        """
        print(f"üß™ Running overfitting test (target loss < {target_loss}, max {max_steps} steps)...")
        
        # Get a single batch
        single_batch = next(iter(self.train_dataloader))
        input_ids = single_batch['input_ids'].to(self.device)
        attention_mask = single_batch.get('attention_mask', None)
        if attention_mask is not None:
            attention_mask = attention_mask.to(self.device)
        
        # Create optimizer for test
        test_optimizer = optim.AdamW(self.model.parameters(), lr=1e-3)
        
        self.model.train()
        
        for step in range(max_steps):
            test_optimizer.zero_grad()
            
            # Forward pass
            outputs = self.model(input_ids, attention_mask=attention_mask, labels=input_ids)
            
            # Calculate loss
            loss_dict = self.loss_function.calculate_total_loss(
                outputs, input_ids, attention_mask, enable_cognitive=False  # Test baseline only
            )
            loss = loss_dict['total_loss']
            
            # Backward pass
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
            test_optimizer.step()
            
            if step % 50 == 0 or loss.item() < target_loss:
                print(f"   Step {step}: loss = {loss.item():.6f}, tokens = {loss_dict['n_tokens']}")
            
            if loss.item() < target_loss:
                print(f"‚úÖ Overfitting test PASSED! Reached loss {loss.item():.6f} < {target_loss} in {step} steps")
                return True
        
        print(f"‚ùå Overfitting test FAILED! Final loss {loss.item():.6f} >= {target_loss} after {max_steps} steps")
        print("   This suggests issues with masking, labels, or model architecture.")
        return False
    
    def train(self, enable_cognitive: bool = True):
        """
        Main training loop with ablation capability.
        
        Args:
            enable_cognitive: Whether to enable cognitive enhancements (False for baseline LM)
        """
        print(f"üöÄ Starting {'Cognitive-Enhanced' if enable_cognitive else 'Baseline LM'} training...")
        print(f"   Model: {sum(p.numel() for p in self.model.parameters())} parameters")
        print(f"   Data: {len(self.train_dataloader)} train batches, {len(self.eval_dataloader) if self.eval_dataloader else 0} eval batches")
        print(f"   Device: {self.device}")
        
        # Run overfitting test first
        if not self.overfitting_test():
            print("‚ö†Ô∏è  Overfitting test failed. Consider checking masking and labels before full training.")
        
        for epoch in range(self.current_epoch, self.config.num_epochs):
            print(f"\nüìö Epoch {epoch + 1}/{self.config.num_epochs}")
            
            epoch_metrics = self.train_epoch(epoch, enable_cognitive=enable_cognitive)
            
            if epoch_metrics is None:  # Early stopping triggered
                break
            
            # Final evaluation for the epoch
            if self.eval_dataloader:
                eval_metrics = self.evaluate(enable_cognitive=enable_cognitive)
                print(f"   Epoch {epoch + 1} Results:")
                print(f"     Train Loss: {epoch_metrics['avg_loss']:.4f}")
                print(f"     Eval Loss: {eval_metrics['eval_loss']:.4f}")
                print(f"     Perplexity: {eval_metrics['perplexity']:.1f}")
                print(f"     Total Tokens: {epoch_metrics['total_tokens']}")
                
                # Log epoch results
                self.writer.add_scalar("epoch/train_loss", epoch_metrics['avg_loss'], epoch)
                self.writer.add_scalar("epoch/eval_loss", eval_metrics['eval_loss'], epoch)
                self.writer.add_scalar("epoch/perplexity", eval_metrics['perplexity'], epoch)
            
            self.current_epoch = epoch + 1
        
        # Final checkpoint
        final_eval_metrics = self.evaluate(enable_cognitive=enable_cognitive) if self.eval_dataloader else {}
        self.checkpoint_manager.save_checkpoint(
            self.model, self.optimizer, self.lr_scheduler,
            self.current_epoch, self.current_step, 
            final_eval_metrics.get('eval_loss', 0.0), 
            eval_metrics=final_eval_metrics
        )
        
        print("üéâ Training completed!")
        self.writer.close()
    
    def _log_training_step(self, loss_dict):
        """Log training step metrics with enhanced details including gradient info."""
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                value = value.item()
            self.writer.add_scalar(f"train/{key}", value, self.current_step)
        
        # Log enhanced metrics
        if 'n_tokens' in loss_dict and 'lm_loss_mean' in loss_dict:
            logging.info(f"Step {self.current_step}: "
                        f"loss_mean={loss_dict['lm_loss_mean']:.4f}, "
                        f"loss_sum={loss_dict['lm_loss_sum']:.4f}, "
                        f"n_tokens={loss_dict['n_tokens']}, "
                        f"seq_len_mean={loss_dict['seq_len_mean']:.1f}, "
                        f"ppl={loss_dict['perplexity']:.1f}, "
                        f"grad_norm={loss_dict.get('grad_norm', 0):.3f}, "
                        f"lr={loss_dict.get('lr', 0):.2e}, "
                        f"scaler_scale={loss_dict.get('scaler_scale', 1.0):.0f}")


def create_trustworthy_training_config():
    """Create default trustworthy training configuration with mixed precision."""
    return TrainingConfig(
        num_epochs=5,
        learning_rate=1e-4,
        cognitive_learning_rate=5e-5,
        weight_decay=0.02,
        warmup_steps=1000,
        max_grad_norm=1.0,
        use_mixed_precision=True,  # Enable mixed precision by default
        save_steps=1000,
        eval_steps=500,
        logging_steps=100,
        max_checkpoints=3,
        gradient_accumulation_steps=4,
        enable_cognitive_enhancement=True,
        cognitive_loss_weight=0.1,
        lr_scheduler_warmup_ratio=0.05,  # Recommended 3-5% warmup
        output_dir="trustworthy_cognitive_llm",
        logging_dir="logs",
        cache_dir="cache"
    )


    def _log_evaluation(self, eval_metrics):
        """Log evaluation metrics with enhanced details."""
        for key, value in eval_metrics.items():
            if isinstance(value, (int, float)):
                self.writer.add_scalar(f"eval/{key}", value, self.current_step)
        
        logging.info(f"Evaluation at step {self.current_step}: {eval_metrics}")


# Alias for compatibility
CognitiveLLMTrainer = TrustworthyCognitiveLLMTrainer


if __name__ == "__main__":
    print("Trustworthy Cognitive LLM Training System Ready!")
    print("Enhanced with:")
    print("  ‚úÖ Per-token loss computation (mean, not sum)")
    print("  ‚úÖ Proper PPL = exp(loss_mean) verification")
    print("  ‚úÖ model.eval() & no_grad() during evaluation")
    print("  ‚úÖ Padding mask sanity (loss weight = 0 for padding)")
    print("  ‚úÖ Label shift verification (labels = input_ids + 1)")
    print("  ‚úÖ Overfitting test for masking/label validation")
    print("  ‚úÖ Clean LM baseline mode (frozen cognition)")
    print("  ‚úÖ Weight decay exclusions (LayerNorm/bias)")
    print("  ‚úÖ Enhanced gradient monitoring with norm logging")
    print("  ‚úÖ Mixed precision training with GradScaler")
    print("  ‚úÖ Cosine LR schedule with 3-5% warmup")
    print("  ‚úÖ Comprehensive ablation framework")