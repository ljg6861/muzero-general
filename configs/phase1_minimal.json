{
    "description": "Phase 1 - Minimal Working Datasets Only",
    "phase": 1,
    "target_tokens": 150000000,
    "mix": {
        "description": "Only proven working datasets",
        "wikipedia": 0.60,
        "wikitext": 0.40
    },
    "data_sources": [
        {
            "name": "wikipedia",
            "dataset": "wikimedia/wikipedia",
            "config_name": "20231101.en",
            "text_field": "text",
            "weight": 0.60,
            "description": "Full Wikipedia English - proven working"
        },
        {
            "name": "wikitext",
            "dataset": "wikitext",
            "config_name": "wikitext-103-raw-v1",
            "text_field": "text",
            "weight": 0.40,
            "description": "Wikitext corpus - proven working"
        }
    ],
    "training": {
        "ctx_len_schedule": {
            "initial": 1024,
            "ramp_to": 2048,
            "ramp_at_tokens": 50000000,
            "long_ctx_percentage": 0.05,
            "long_ctx_len": 4096,
            "long_ctx_start_tokens": 100000000
        },
        "sampling": {
            "temperature": 0.7,
            "description": "Up-weight rare/high-value shards"
        },
        "sequence_packing": true,
        "cross_doc_attention": false,
        "shuffle_documents": true
    },
    "model": {
        "name": "UnifiedCognitiveLM",
        "hidden_size": 768,
        "num_layers": 12,
        "num_heads": 12,
        "max_seq_length": 2048,
        "vocab_size": 50258,
        "router_supervision": true,
        "schema_inference": true,
        "hybrid_memory": true,
        "self_correction": true
    },
    "optimization": {
        "learning_rate": 5e-4,
        "weight_decay": 0.1,
        "beta1": 0.9,
        "beta2": 0.95,
        "batch_size": 8,
        "accumulation_steps": 4,
        "gradient_checkpointing": true,
        "max_grad_norm": 1.0
    },
    "scheduling": {
        "warmup_tokens": 10000000,
        "lr_decay": "cosine",
        "min_lr_ratio": 0.1
    },
    "evaluation": {
        "eval_tokens": 1500000,
        "eval_interval": 1000,
        "save_interval": 5000
    }
}